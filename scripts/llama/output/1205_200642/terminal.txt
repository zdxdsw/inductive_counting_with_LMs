-------- Preparing model and tokenizer --------
-------- Preparing data --------
num train = 126000
num val = 12600

example data: 
### Question: What is "117197313723708179861276453394127515945682856398897952451433596627553721268 + 469336947859953324085800578681314399008782872709193358956844220046062455939"?
 ### Answer: 586534261583661503947077032075441914954465729108091311408277816673616177207.</s> 
-------- Preparing LoRA --------
Total parameters: 6746812416
Trainable parameters: 8388608
response template tokens: ['▁###', '▁Answer', ':']
{'loss': 0.6771, 'learning_rate': 0.0001, 'epoch': 0.13}
{'loss': 0.0501, 'learning_rate': 0.0001, 'epoch': 0.25}
{'loss': 0.0309, 'learning_rate': 0.0001, 'epoch': 0.38}
{'loss': 0.0213, 'learning_rate': 0.0001, 'epoch': 0.51}
{'loss': 0.0159, 'learning_rate': 0.0001, 'epoch': 0.63}
{'loss': 0.0132, 'learning_rate': 0.0001, 'epoch': 0.76}
{'loss': 0.0106, 'learning_rate': 0.0001, 'epoch': 0.89}
{'eval_loss': 0.010398823767900467, 'eval_accuracy': 0.7596825396825397, 'eval_runtime': 168.0592, 'eval_samples_per_second': 74.974, 'eval_steps_per_second': 1.172, 'epoch': 1.0}
{'loss': 0.0081, 'learning_rate': 0.0001, 'epoch': 1.02}
{'loss': 0.0071, 'learning_rate': 0.0001, 'epoch': 1.14}
{'loss': 0.0069, 'learning_rate': 0.0001, 'epoch': 1.27}
{'loss': 0.0055, 'learning_rate': 0.0001, 'epoch': 1.4}
{'loss': 0.0053, 'learning_rate': 0.0001, 'epoch': 1.52}
{'loss': 0.0047, 'learning_rate': 0.0001, 'epoch': 1.65}
{'loss': 0.0043, 'learning_rate': 0.0001, 'epoch': 1.78}
{'loss': 0.0037, 'learning_rate': 0.0001, 'epoch': 1.9}
{'eval_loss': 0.004764051176607609, 'eval_accuracy': 0.8738888888888889, 'eval_runtime': 165.4892, 'eval_samples_per_second': 76.138, 'eval_steps_per_second': 1.19, 'epoch': 2.0}
{'loss': 0.0034, 'learning_rate': 0.0001, 'epoch': 2.03}
{'loss': 0.0029, 'learning_rate': 0.0001, 'epoch': 2.16}
{'loss': 0.0028, 'learning_rate': 0.0001, 'epoch': 2.29}
{'loss': 0.0026, 'learning_rate': 0.0001, 'epoch': 2.41}
{'loss': 0.0066, 'learning_rate': 0.0001, 'epoch': 2.54}
{'loss': 0.0021, 'learning_rate': 0.0001, 'epoch': 2.67}
{'loss': 0.002, 'learning_rate': 0.0001, 'epoch': 2.79}
{'loss': 0.0022, 'learning_rate': 0.0001, 'epoch': 2.92}
{'eval_loss': 0.0012235664762556553, 'eval_accuracy': 0.9674603174603175, 'eval_runtime': 165.4679, 'eval_samples_per_second': 76.148, 'eval_steps_per_second': 1.191, 'epoch': 3.0}
{'loss': 0.0017, 'learning_rate': 0.0001, 'epoch': 3.05}
{'loss': 0.0017, 'learning_rate': 0.0001, 'epoch': 3.17}
{'loss': 0.0019, 'learning_rate': 0.0001, 'epoch': 3.3}
{'loss': 0.0017, 'learning_rate': 0.0001, 'epoch': 3.43}
{'loss': 0.0015, 'learning_rate': 0.0001, 'epoch': 3.56}
{'loss': 0.0011, 'learning_rate': 0.0001, 'epoch': 3.68}
{'loss': 0.0013, 'learning_rate': 0.0001, 'epoch': 3.81}
{'loss': 0.0012, 'learning_rate': 0.0001, 'epoch': 3.94}
{'eval_loss': 0.0009797647362574935, 'eval_accuracy': 0.9742063492063492, 'eval_runtime': 165.6299, 'eval_samples_per_second': 76.073, 'eval_steps_per_second': 1.189, 'epoch': 4.0}
{'loss': 0.001, 'learning_rate': 0.0001, 'epoch': 4.06}
{'loss': 0.0032, 'learning_rate': 0.0001, 'epoch': 4.19}
{'loss': 0.001, 'learning_rate': 0.0001, 'epoch': 4.32}
{'loss': 0.001, 'learning_rate': 0.0001, 'epoch': 4.44}
{'loss': 0.001, 'learning_rate': 0.0001, 'epoch': 4.57}
{'loss': 0.0009, 'learning_rate': 0.0001, 'epoch': 4.7}
{'loss': 0.0009, 'learning_rate': 0.0001, 'epoch': 4.83}
{'loss': 0.001, 'learning_rate': 0.0001, 'epoch': 4.95}
{'eval_loss': 0.0005053201457485557, 'eval_accuracy': 0.9841269841269841, 'eval_runtime': 165.613, 'eval_samples_per_second': 76.081, 'eval_steps_per_second': 1.19, 'epoch': 5.0}
{'loss': 0.0008, 'learning_rate': 0.0001, 'epoch': 5.08}
{'loss': 0.0006, 'learning_rate': 0.0001, 'epoch': 5.21}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 5.33}
{'loss': 0.0124, 'learning_rate': 0.0001, 'epoch': 5.46}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 5.59}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 5.71}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 5.84}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 5.97}
{'eval_loss': 0.0005031892214901745, 'eval_accuracy': 0.984920634920635, 'eval_runtime': 165.7457, 'eval_samples_per_second': 76.02, 'eval_steps_per_second': 1.189, 'epoch': 6.0}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 6.1}
{'loss': 0.0006, 'learning_rate': 0.0001, 'epoch': 6.22}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 6.35}
{'loss': 0.0008, 'learning_rate': 0.0001, 'epoch': 6.48}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 6.6}
{'loss': 0.0093, 'learning_rate': 0.0001, 'epoch': 6.73}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 6.86}
{'loss': 0.0006, 'learning_rate': 0.0001, 'epoch': 6.98}
{'eval_loss': 0.000499825575388968, 'eval_accuracy': 0.991984126984127, 'eval_runtime': 165.7285, 'eval_samples_per_second': 76.028, 'eval_steps_per_second': 1.189, 'epoch': 7.0}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 7.11}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 7.24}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 7.37}
{'loss': 0.0006, 'learning_rate': 0.0001, 'epoch': 7.49}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 7.62}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 7.75}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 7.87}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 8.0}
{'eval_loss': 0.0005449724849313498, 'eval_accuracy': 0.99, 'eval_runtime': 165.5732, 'eval_samples_per_second': 76.099, 'eval_steps_per_second': 1.19, 'epoch': 8.0}
{'loss': 0.0048, 'learning_rate': 0.0001, 'epoch': 8.13}
{'loss': 0.0007, 'learning_rate': 0.0001, 'epoch': 8.25}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 8.38}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 8.51}
{'loss': 0.0011, 'learning_rate': 0.0001, 'epoch': 8.63}
{'loss': 0.0012, 'learning_rate': 0.0001, 'epoch': 8.76}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 8.89}
{'eval_loss': 0.00027160553145222366, 'eval_accuracy': 0.9934126984126984, 'eval_runtime': 165.4595, 'eval_samples_per_second': 76.152, 'eval_steps_per_second': 1.191, 'epoch': 9.0}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 9.02}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 9.14}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 9.27}
{'loss': 0.0005, 'learning_rate': 0.0001, 'epoch': 9.4}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 9.52}
{'loss': 0.0003, 'learning_rate': 0.0001, 'epoch': 9.65}
{'loss': 0.0004, 'learning_rate': 0.0001, 'epoch': 9.78}
{'loss': 0.0002, 'learning_rate': 0.0001, 'epoch': 9.9}
{'eval_loss': 0.0002571334771346301, 'eval_accuracy': 0.9920634920634921, 'eval_runtime': 165.3411, 'eval_samples_per_second': 76.206, 'eval_steps_per_second': 1.191, 'epoch': 10.0}
{'train_runtime': 54109.4608, 'train_samples_per_second': 23.286, 'train_steps_per_second': 1.455, 'train_loss': 0.012160011790858375, 'epoch': 10.0}
