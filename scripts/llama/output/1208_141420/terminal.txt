-------- Preparing model and tokenizer --------
-------- Preparing data --------
num train = 5900
num val = 5900

example data: 
### Question: What is the most common digit in the string "587458549847365763853586743365505642665680"?
 ### Answer: 5.</s> 
-------- Preparing LoRA --------
Total parameters: 6746812416
Trainable parameters: 8388608
response template tokens: ['▁###', '▁Answer', ':']
{'loss': 2.3682, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.54}
{'eval_loss': 0.013531199656426907, 'eval_accuracy': 0.9745762711864406, 'eval_runtime': 26.387, 'eval_samples_per_second': 223.595, 'eval_steps_per_second': 3.524, 'epoch': 1.0}
{'loss': 0.0272, 'learning_rate': 0.0001, 'epoch': 1.08}
{'loss': 0.0163, 'learning_rate': 0.0001, 'epoch': 1.63}
{'eval_loss': 0.01002136617898941, 'eval_accuracy': 0.9813559322033898, 'eval_runtime': 26.4082, 'eval_samples_per_second': 223.416, 'eval_steps_per_second': 3.522, 'epoch': 2.0}
{'loss': 0.0114, 'learning_rate': 0.0001, 'epoch': 2.17}
{'loss': 0.0096, 'learning_rate': 0.0001, 'epoch': 2.71}
{'eval_loss': 0.007613071706146002, 'eval_accuracy': 0.9847457627118644, 'eval_runtime': 26.3356, 'eval_samples_per_second': 224.032, 'eval_steps_per_second': 3.531, 'epoch': 3.0}
{'loss': 0.0093, 'learning_rate': 0.0001, 'epoch': 3.25}
{'loss': 0.0059, 'learning_rate': 0.0001, 'epoch': 3.79}
{'eval_loss': 0.00910502765327692, 'eval_accuracy': 0.9838983050847457, 'eval_runtime': 26.2148, 'eval_samples_per_second': 225.063, 'eval_steps_per_second': 3.548, 'epoch': 4.0}
{'loss': 0.0052, 'learning_rate': 0.0001, 'epoch': 4.34}
{'loss': 0.0064, 'learning_rate': 0.0001, 'epoch': 4.88}
{'eval_loss': 0.016044728457927704, 'eval_accuracy': 0.9723728813559323, 'eval_runtime': 26.1607, 'eval_samples_per_second': 225.529, 'eval_steps_per_second': 3.555, 'epoch': 5.0}
{'loss': 0.0042, 'learning_rate': 0.0001, 'epoch': 5.42}
{'loss': 0.004, 'learning_rate': 0.0001, 'epoch': 5.96}
{'eval_loss': 0.006776437163352966, 'eval_accuracy': 0.988135593220339, 'eval_runtime': 26.1372, 'eval_samples_per_second': 225.732, 'eval_steps_per_second': 3.558, 'epoch': 6.0}
{'loss': 0.0019, 'learning_rate': 0.0001, 'epoch': 6.5}
{'eval_loss': 0.010213793255388737, 'eval_accuracy': 0.9810169491525423, 'eval_runtime': 26.1981, 'eval_samples_per_second': 225.207, 'eval_steps_per_second': 3.55, 'epoch': 7.0}
{'loss': 0.0032, 'learning_rate': 0.0001, 'epoch': 7.05}
{'loss': 0.0036, 'learning_rate': 0.0001, 'epoch': 7.59}
{'eval_loss': 0.009453179314732552, 'eval_accuracy': 0.9837288135593221, 'eval_runtime': 26.1841, 'eval_samples_per_second': 225.327, 'eval_steps_per_second': 3.552, 'epoch': 8.0}
{'loss': 0.0064, 'learning_rate': 0.0001, 'epoch': 8.13}
{'loss': 0.0057, 'learning_rate': 0.0001, 'epoch': 8.67}
{'eval_loss': 0.005696883890777826, 'eval_accuracy': 0.9889830508474576, 'eval_runtime': 26.1659, 'eval_samples_per_second': 225.484, 'eval_steps_per_second': 3.554, 'epoch': 9.0}
{'loss': 0.0019, 'learning_rate': 0.0001, 'epoch': 9.21}
{'loss': 0.0032, 'learning_rate': 0.0001, 'epoch': 9.76}
{'eval_loss': 0.01446788851171732, 'eval_accuracy': 0.9786440677966102, 'eval_runtime': 26.1993, 'eval_samples_per_second': 225.197, 'eval_steps_per_second': 3.55, 'epoch': 10.0}
{'train_runtime': 1175.5864, 'train_samples_per_second': 50.188, 'train_steps_per_second': 3.139, 'train_loss': 0.1352045383152923, 'epoch': 10.0}
