-------- Preparing model and tokenizer --------
-------- Preparing data --------
num train = 12600
num val = 12600

example data: 
### Question: What is "210740261826753338185030700851593170680931869598541271350463257056846873524 + 461469973259196333827874076240074361196729819911900772056722486109169846946"?
 ### Answer: 672210235085949672012904777091667531877661689510442043407185743166016720470.</s> 
-------- Preparing LoRA --------
Total parameters: 6746812416
Trainable parameters: 8388608
response template tokens: ['▁###', '▁Answer', ':']
{'loss': 1.8722, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.25}
{'loss': 0.8809, 'learning_rate': 0.0001, 'epoch': 0.51}
{'loss': 0.4066, 'learning_rate': 0.0001, 'epoch': 0.76}
{'eval_loss': 0.12716373801231384, 'eval_accuracy': 0.18047619047619048, 'eval_runtime': 168.5531, 'eval_samples_per_second': 74.754, 'eval_steps_per_second': 1.169, 'epoch': 1.0}
{'loss': 0.114, 'learning_rate': 0.0001, 'epoch': 1.02}
{'loss': 0.0846, 'learning_rate': 0.0001, 'epoch': 1.27}
{'loss': 0.0668, 'learning_rate': 0.0001, 'epoch': 1.52}
{'loss': 0.0523, 'learning_rate': 0.0001, 'epoch': 1.78}
{'eval_loss': 0.04584212228655815, 'eval_accuracy': 0.33746031746031746, 'eval_runtime': 165.4247, 'eval_samples_per_second': 76.168, 'eval_steps_per_second': 1.191, 'epoch': 2.0}
{'loss': 0.0482, 'learning_rate': 0.0001, 'epoch': 2.03}
{'loss': 0.0407, 'learning_rate': 0.0001, 'epoch': 2.29}
{'loss': 0.0336, 'learning_rate': 0.0001, 'epoch': 2.54}
{'loss': 0.0327, 'learning_rate': 0.0001, 'epoch': 2.79}
{'eval_loss': 0.030712386593222618, 'eval_accuracy': 0.44976190476190475, 'eval_runtime': 165.4607, 'eval_samples_per_second': 76.151, 'eval_steps_per_second': 1.191, 'epoch': 3.0}
{'loss': 0.0298, 'learning_rate': 0.0001, 'epoch': 3.05}
{'loss': 0.0261, 'learning_rate': 0.0001, 'epoch': 3.3}
{'loss': 0.0256, 'learning_rate': 0.0001, 'epoch': 3.56}
{'loss': 0.0259, 'learning_rate': 0.0001, 'epoch': 3.81}
{'eval_loss': 0.022903313860297203, 'eval_accuracy': 0.56, 'eval_runtime': 165.5587, 'eval_samples_per_second': 76.106, 'eval_steps_per_second': 1.19, 'epoch': 4.0}
{'loss': 0.0208, 'learning_rate': 0.0001, 'epoch': 4.06}
{'loss': 0.0185, 'learning_rate': 0.0001, 'epoch': 4.32}
{'loss': 0.0179, 'learning_rate': 0.0001, 'epoch': 4.57}
{'loss': 0.0177, 'learning_rate': 0.0001, 'epoch': 4.83}
{'eval_loss': 0.016859544441103935, 'eval_accuracy': 0.6507936507936508, 'eval_runtime': 165.4592, 'eval_samples_per_second': 76.152, 'eval_steps_per_second': 1.191, 'epoch': 5.0}
{'loss': 0.0166, 'learning_rate': 0.0001, 'epoch': 5.08}
{'loss': 0.0145, 'learning_rate': 0.0001, 'epoch': 5.33}
{'loss': 0.0127, 'learning_rate': 0.0001, 'epoch': 5.59}
{'loss': 0.0132, 'learning_rate': 0.0001, 'epoch': 5.84}
{'eval_loss': 0.015004083514213562, 'eval_accuracy': 0.6811111111111111, 'eval_runtime': 165.425, 'eval_samples_per_second': 76.167, 'eval_steps_per_second': 1.191, 'epoch': 6.0}
{'loss': 0.013, 'learning_rate': 0.0001, 'epoch': 6.1}
{'loss': 0.0115, 'learning_rate': 0.0001, 'epoch': 6.35}
{'loss': 0.0113, 'learning_rate': 0.0001, 'epoch': 6.6}
{'loss': 0.0106, 'learning_rate': 0.0001, 'epoch': 6.86}
{'eval_loss': 0.01580171473324299, 'eval_accuracy': 0.6652380952380952, 'eval_runtime': 165.5873, 'eval_samples_per_second': 76.093, 'eval_steps_per_second': 1.19, 'epoch': 7.0}
{'loss': 0.0106, 'learning_rate': 0.0001, 'epoch': 7.11}
{'loss': 0.009, 'learning_rate': 0.0001, 'epoch': 7.37}
{'loss': 0.0095, 'learning_rate': 0.0001, 'epoch': 7.62}
{'loss': 0.0089, 'learning_rate': 0.0001, 'epoch': 7.87}
{'eval_loss': 0.012536241672933102, 'eval_accuracy': 0.7386507936507937, 'eval_runtime': 165.5662, 'eval_samples_per_second': 76.103, 'eval_steps_per_second': 1.19, 'epoch': 8.0}
{'loss': 0.0086, 'learning_rate': 0.0001, 'epoch': 8.13}
{'loss': 0.0081, 'learning_rate': 0.0001, 'epoch': 8.38}
{'loss': 0.0082, 'learning_rate': 0.0001, 'epoch': 8.63}
{'loss': 0.0078, 'learning_rate': 0.0001, 'epoch': 8.89}
{'eval_loss': 0.015879184007644653, 'eval_accuracy': 0.6913492063492064, 'eval_runtime': 165.6219, 'eval_samples_per_second': 76.077, 'eval_steps_per_second': 1.189, 'epoch': 9.0}
{'loss': 0.0073, 'learning_rate': 0.0001, 'epoch': 9.14}
{'loss': 0.0068, 'learning_rate': 0.0001, 'epoch': 9.4}
{'loss': 0.0065, 'learning_rate': 0.0001, 'epoch': 9.65}
{'loss': 0.0074, 'learning_rate': 0.0001, 'epoch': 9.9}
{'eval_loss': 0.015889847651124, 'eval_accuracy': 0.7374603174603175, 'eval_runtime': 165.5393, 'eval_samples_per_second': 76.115, 'eval_steps_per_second': 1.19, 'epoch': 9.99}
{'train_runtime': 6955.5216, 'train_samples_per_second': 18.115, 'train_steps_per_second': 1.131, 'train_loss': 0.10214230141009581, 'epoch': 9.99}
