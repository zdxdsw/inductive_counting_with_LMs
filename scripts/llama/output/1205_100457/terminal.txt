-------- Preparing model and tokenizer --------
-------- Preparing data --------
num train = 6300
num val = 12600

example data: 
### Question: What is length of the string "252333929135692680177890494470101030488139674051355897694880452584394552986"?
 ### Answer: 75.</s> 
-------- Preparing LoRA --------
Total parameters: 6746812416
Trainable parameters: 8388608
response template tokens: ['▁###', '▁Answer', ':']
{'loss': 4.5531, 'learning_rate': 4.9e-05, 'epoch': 0.25}
{'loss': 0.7251, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.51}
{'loss': 0.5652, 'learning_rate': 0.0001, 'epoch': 0.76}
{'eval_loss': 1.1178953647613525, 'eval_accuracy': 0.07880952380952382, 'eval_runtime': 74.5861, 'eval_samples_per_second': 168.932, 'eval_steps_per_second': 2.641, 'epoch': 1.0}
{'loss': 0.4812, 'learning_rate': 0.0001, 'epoch': 1.02}
{'loss': 0.412, 'learning_rate': 0.0001, 'epoch': 1.27}
{'loss': 0.5137, 'learning_rate': 0.0001, 'epoch': 1.52}
{'loss': 0.3897, 'learning_rate': 0.0001, 'epoch': 1.78}
{'eval_loss': 0.877360463142395, 'eval_accuracy': 0.2958730158730159, 'eval_runtime': 73.3549, 'eval_samples_per_second': 171.768, 'eval_steps_per_second': 2.686, 'epoch': 2.0}
{'loss': 0.2823, 'learning_rate': 0.0001, 'epoch': 2.03}
{'loss': 0.1215, 'learning_rate': 0.0001, 'epoch': 2.28}
{'loss': 0.0165, 'learning_rate': 0.0001, 'epoch': 2.54}
{'loss': 0.0016, 'learning_rate': 0.0001, 'epoch': 2.79}
{'eval_loss': 1.1666882038116455, 'eval_accuracy': 0.5, 'eval_runtime': 74.0646, 'eval_samples_per_second': 170.122, 'eval_steps_per_second': 2.66, 'epoch': 3.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 3.05}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 3.3}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 3.55}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 3.81}
{'eval_loss': 1.224792242050171, 'eval_accuracy': 0.5, 'eval_runtime': 73.6914, 'eval_samples_per_second': 170.983, 'eval_steps_per_second': 2.673, 'epoch': 4.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 4.06}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 4.31}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 4.57}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 4.82}
{'eval_loss': 1.2453066110610962, 'eval_accuracy': 0.5, 'eval_runtime': 74.2907, 'eval_samples_per_second': 169.604, 'eval_steps_per_second': 2.652, 'epoch': 5.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 5.08}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 5.33}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 5.58}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 5.84}
{'eval_loss': 1.2621442079544067, 'eval_accuracy': 0.5, 'eval_runtime': 73.9269, 'eval_samples_per_second': 170.439, 'eval_steps_per_second': 2.665, 'epoch': 6.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 6.09}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 6.35}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 6.6}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 6.85}
{'eval_loss': 1.275694489479065, 'eval_accuracy': 0.5, 'eval_runtime': 73.8221, 'eval_samples_per_second': 170.68, 'eval_steps_per_second': 2.669, 'epoch': 7.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 7.11}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 7.36}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 7.61}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 7.87}
{'eval_loss': 1.290065050125122, 'eval_accuracy': 0.5, 'eval_runtime': 74.2135, 'eval_samples_per_second': 169.78, 'eval_steps_per_second': 2.655, 'epoch': 8.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 8.12}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 8.38}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 8.63}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 8.88}
{'eval_loss': 1.301427960395813, 'eval_accuracy': 0.5, 'eval_runtime': 74.0753, 'eval_samples_per_second': 170.097, 'eval_steps_per_second': 2.659, 'epoch': 9.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 9.14}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 9.39}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 9.64}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 9.9}
{'eval_loss': 1.3124711513519287, 'eval_accuracy': 0.5, 'eval_runtime': 74.2083, 'eval_samples_per_second': 169.792, 'eval_steps_per_second': 2.655, 'epoch': 10.0}
{'train_runtime': 1954.3631, 'train_samples_per_second': 32.236, 'train_steps_per_second': 2.016, 'train_loss': 0.20461830085108942, 'epoch': 10.0}
