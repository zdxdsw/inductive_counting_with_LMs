{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, math, sys, random, re, pytz\n",
    "from datetime import datetime\n",
    "timezone = pytz.timezone('America/New_York') \n",
    "import torch\n",
    "sys.path.append(\"../scripts/\")\n",
    "from causal_transformer.model import Causal_Transformer\n",
    "from causal_transformer.config import *\n",
    "from causal_transformer.dataset import sequences_collator\n",
    "from causal_transformer.utils import get_acc\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from 9_343750_transformer.pt\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "task = \"counting_samesymbol_addbigram\"\n",
    "config = eval(f\"{task}_Config()\")\n",
    "ckpt_dir = \"/data/yingshac/llms_do_math/scripts/causal_transformer/output\"\n",
    "\n",
    "load_from_dir = \"0423_205349\"\n",
    "load_from_specific_epc = 10\n",
    "\n",
    "load_from_config = json.load(open(os.path.join(\"../scripts/causal_transformer/output\", load_from_dir, \"config.json\"), \"r\"))\n",
    "for k in load_from_config:\n",
    "    setattr(config, k, load_from_config[k])\n",
    "if not \"tie_word_embeddings\" in load_from_config: config.tie_word_embeddings = False # for backward compatibility\n",
    "model = Causal_Transformer(config)\n",
    "model = model.to(device)\n",
    "\n",
    "ckpt_dir = os.path.join(ckpt_dir, load_from_dir, \"ckpts\")\n",
    "if load_from_specific_epc is None:\n",
    "    load_from_pt = sorted(os.listdir(ckpt_dir), key=lambda x: int(x.split(\"_\")[1]))[-1]\n",
    "else:\n",
    "    load_from_pt = sorted([x for x in os.listdir(ckpt_dir) if f\"{load_from_specific_epc-1}_\" in x[:4]], key=lambda x: int(x.split(\"_\")[1]))[-1]\n",
    "state_dict = torch.load(os.path.join(ckpt_dir, load_from_pt), map_location=device)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "print(f\"load from {load_from_pt}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0090,  0.0336,  0.0754,  0.0996], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.2037, -0.2519, -0.2904, -0.2606], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.wte.weight[60:64, 180])\n",
    "print(model.lm_head.weight[60:64, 180])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num ood_test data = 50\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"../data/rasp_primitives/{task}\"\n",
    "split = \"ood_test\"\n",
    "test_data = load_dataset(\n",
    "                    \"text\", \n",
    "                    data_files={split: f\"{data_path}/{split}.txt\"})\n",
    "print(f\"num {split} data = {len(test_data[split])}\")\n",
    "\n",
    "if config.absolute_posemb_shift or config.rotary_posemb_shift:\n",
    "    augmentation = \"shift\"\n",
    "elif config.absolute_posemb_rdmz or config.rotary_posemb_rdmz:\n",
    "    augmentation = \"randomized\"\n",
    "collator = partial(sequences_collator, \n",
    "                   w2i={w:i for i,w in enumerate(config.vocab)}, \n",
    "                   max_len=config.max_position_embeddings,\n",
    "                   augmentation=augmentation,\n",
    "                   )\n",
    "test_dataloader = DataLoader(test_data[split], shuffle=False, batch_size=config.per_device_train_batch_size, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ood_test acc\n",
      "        | Test Loss: 0.0 \n",
      "        | Test Acc: 1.0 \n",
      "        | Test Counting Acc: 1.0 \n",
      "        | Test Last Acc: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "counting_correct, counting_demo, last_correct, last_demo, correct, demo = 0, 0, 0, 0, 0, 0\n",
    "test_losses = []\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "model.eval()\n",
    "testing_output = {}\n",
    "\n",
    "date = datetime.now(timezone).strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "k = 0\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    position_ids = None\n",
    "    if batch['position_id'] is not None: position_ids = batch['position_id'].to(device)\n",
    "    \n",
    "    logits = model(\n",
    "        batch['input_id'].to(device),\n",
    "        position_ids = position_ids,\n",
    "        attention_mask = batch['attention_mask'].to(device),\n",
    "    )\n",
    "\n",
    "    loss = criterion(\n",
    "        logits.view(-1, logits.size(-1)), # bs*seq_len, vocab_size\n",
    "        batch['label'].view(-1).to(device), # 1, bs*seq_len\n",
    "    )\n",
    "    test_losses.append(loss.detach().item())\n",
    "    _counting_correct, _counting_demo, _last_correct, _last_demo = get_acc(logits.detach().cpu(), batch['label'].detach().cpu(), ignore_index=-1)\n",
    "    counting_correct += _counting_correct\n",
    "    counting_demo += _counting_demo\n",
    "    last_correct += _last_correct\n",
    "    last_demo += _last_demo\n",
    "    correct += (_counting_correct + _last_correct)\n",
    "    demo += (_counting_demo + _last_demo)\n",
    "   \n",
    "    for input_id, gth_id, pred_id in zip(batch['input_id'], batch['label'], logits.argmax(dim=-1)):\n",
    "        input_seq = [config.vocab[i] for i in input_id if config.vocab[i]!='<pad>']\n",
    "        gth_seq = [config.vocab[gth_id[i]] for i in range(len(gth_id)) if gth_id[i]!=-1]\n",
    "        pred_seq = [config.vocab[pred_id[i]] for i in range(len(gth_id)) if gth_id[i]!=-1][:len(gth_seq)]\n",
    "        testing_output[k] = {\n",
    "            \"input\": \" \".join(input_seq),\n",
    "            \"gth\": \" \".join(gth_seq),\n",
    "            \"pred\": \" \".join(pred_seq),\n",
    "        }\n",
    "        k+=1\n",
    "    \n",
    "print(f\"\"\" {split} acc\n",
    "        | Test Loss: {round(np.mean(test_losses), 4)} \n",
    "        | Test Acc: {round(correct/demo, 4)} \n",
    "        | Test Counting Acc: {round(counting_correct/counting_demo, 4)} \n",
    "        | Test Last Acc: {round(last_correct/last_demo, 4)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"../scripts/causal_transformer/output/{load_from_dir}/test_samples\", exist_ok=True)\n",
    "json.dump({\n",
    "        \"test_data_file\":  f\"{data_path}/{split}.txt\",\n",
    "        \"load_from\": f\"{load_from_dir}/{load_from_pt}\",\n",
    "        \"test_acc\": round(correct/demo, 4),\n",
    "        \"test_counting_acc\": round(counting_correct/counting_demo, 4),\n",
    "        \"test_last_acc\": round(last_correct/last_demo, 4),\n",
    "        \"test_loss\": round(np.mean(test_losses), 4),\n",
    "        \"testing_output\": testing_output,\n",
    "    }, \n",
    "    open(f\"../scripts/causal_transformer/output/{load_from_dir}/test_samples/{date}.json\", \"w\"), indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_last_acc = 0.28\n",
      "avg_unseen_len_acc = 0.4784\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "J = json.load(open(f\"../scripts/causal_transformer/output/0422_172246/test_samples/0422_185531_9.json\", \"r\"))['testing_output']\n",
    "last_correct, last_demo = 0, 0\n",
    "unseen_len_correct, unseen_len_demo = 0, 0\n",
    "for k in J:\n",
    "    gth = np.array([int(x) for x in J[k]['gth'].split()])\n",
    "    pred = np.array([int(x) for x in J[k]['pred'].split()])\n",
    "    last_correct += int(gth[-1] == pred[-1])\n",
    "    last_demo += 1\n",
    "    unseen_len_correct += (gth[50:] == pred[50:]).sum()\n",
    "    unseen_len_demo += len(gth[50:])\n",
    "print(f\"avg_last_acc = {round(last_correct/last_demo, 4)}\")\n",
    "print(f\"avg_unseen_len_acc = {round(unseen_len_correct/unseen_len_demo, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(J[k]['gth'][50:]) == np.array(J[k]['pred'][50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary (In the order of forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "task = \"counting_selective_padhelper\"\n",
    "config = eval(f\"{task}_Config()\")\n",
    "config.absolute_posemb_shift = False\n",
    "config.rotary_posemb_shift = False\n",
    "config.absolute_posemb = False\n",
    "config.rotary_posemb = False\n",
    "config.num_hidden_layers = 2\n",
    "config.embd_pdrop = 0.1\n",
    "config.attn_pdrop = 0.1\n",
    "config.resid_pdrop = 0.1\n",
    "\n",
    "model = Causal_Transformer(config)\n",
    "model = model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================\n",
      "Layer (type (var_name))                       Kernel Shape     Param #          Param %\n",
      "=============================================================================================\n",
      "Causal_Transformer (Causal_Transformer)       --               --                    --\n",
      "├─Embedding (wte)                             --               55,296             0.22%\n",
      "│    └─weight                                 [1024, 54]       └─55,296\n",
      "├─Dropout (drop)                              --               --                    --\n",
      "├─ModuleList (h)                              --               --                    --\n",
      "│    └─0.ln_1.weight                          [1024]           ├─1,024\n",
      "│    └─0.ln_1.bias                            [1024]           ├─1,024\n",
      "│    └─0.attn.c_attn.weight                   [1024, 3072]     ├─3,145,728\n",
      "│    └─0.attn.c_attn.bias                     [3072]           ├─3,072\n",
      "│    └─0.attn.c_proj.weight                   [1024, 1024]     ├─1,048,576\n",
      "│    └─0.attn.c_proj.bias                     [1024]           ├─1,024\n",
      "│    └─0.ln_2.weight                          [1024]           ├─1,024\n",
      "│    └─0.ln_2.bias                            [1024]           ├─1,024\n",
      "│    └─0.mlp.c_fc.weight                      [1024, 4096]     ├─4,194,304\n",
      "│    └─0.mlp.c_fc.bias                        [4096]           ├─4,096\n",
      "│    └─0.mlp.c_proj.weight                    [4096, 1024]     ├─4,194,304\n",
      "│    └─0.mlp.c_proj.bias                      [1024]           ├─1,024\n",
      "│    └─1.ln_1.weight                          [1024]           ├─1,024\n",
      "│    └─1.ln_1.bias                            [1024]           ├─1,024\n",
      "│    └─1.attn.c_attn.weight                   [1024, 3072]     ├─3,145,728\n",
      "│    └─1.attn.c_attn.bias                     [3072]           ├─3,072\n",
      "│    └─1.attn.c_proj.weight                   [1024, 1024]     ├─1,048,576\n",
      "│    └─1.attn.c_proj.bias                     [1024]           ├─1,024\n",
      "│    └─1.ln_2.weight                          [1024]           ├─1,024\n",
      "│    └─1.ln_2.bias                            [1024]           ├─1,024\n",
      "│    └─1.mlp.c_fc.weight                      [1024, 4096]     ├─4,194,304\n",
      "│    └─1.mlp.c_fc.bias                        [4096]           ├─4,096\n",
      "│    └─1.mlp.c_proj.weight                    [4096, 1024]     ├─4,194,304\n",
      "│    └─1.mlp.c_proj.bias                      [1024]           └─1,024\n",
      "│    └─Block (0)                              --               --                    --\n",
      "│    │    └─ln_1.weight                       [1024]           ├─1,024\n",
      "│    │    └─ln_1.bias                         [1024]           ├─1,024\n",
      "│    │    └─attn.c_attn.weight                [1024, 3072]     ├─3,145,728\n",
      "│    │    └─attn.c_attn.bias                  [3072]           ├─3,072\n",
      "│    │    └─attn.c_proj.weight                [1024, 1024]     ├─1,048,576\n",
      "│    │    └─attn.c_proj.bias                  [1024]           ├─1,024\n",
      "│    │    └─ln_2.weight                       [1024]           ├─1,024\n",
      "│    │    └─ln_2.bias                         [1024]           ├─1,024\n",
      "│    │    └─mlp.c_fc.weight                   [1024, 4096]     ├─4,194,304\n",
      "│    │    └─mlp.c_fc.bias                     [4096]           ├─4,096\n",
      "│    │    └─mlp.c_proj.weight                 [4096, 1024]     ├─4,194,304\n",
      "│    │    └─mlp.c_proj.bias                   [1024]           └─1,024\n",
      "│    │    └─LayerNorm (ln_1)                  --               2,048              0.01%\n",
      "│    │    │    └─weight                       [1024]           ├─1,024\n",
      "│    │    │    └─bias                         [1024]           └─1,024\n",
      "│    │    └─Attention (attn)                  --               4,198,400         16.59%\n",
      "│    │    │    └─c_attn.weight                [1024, 3072]     ├─3,145,728\n",
      "│    │    │    └─c_attn.bias                  [3072]           ├─3,072\n",
      "│    │    │    └─c_proj.weight                [1024, 1024]     ├─1,048,576\n",
      "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
      "│    │    └─LayerNorm (ln_2)                  --               2,048              0.01%\n",
      "│    │    │    └─weight                       [1024]           ├─1,024\n",
      "│    │    │    └─bias                         [1024]           └─1,024\n",
      "│    │    └─MLP (mlp)                         --               8,393,728         33.17%\n",
      "│    │    │    └─c_fc.weight                  [1024, 4096]     ├─4,194,304\n",
      "│    │    │    └─c_fc.bias                    [4096]           ├─4,096\n",
      "│    │    │    └─c_proj.weight                [4096, 1024]     ├─4,194,304\n",
      "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
      "│    └─Block (1)                              --               --                    --\n",
      "│    │    └─ln_1.weight                       [1024]           ├─1,024\n",
      "│    │    └─ln_1.bias                         [1024]           ├─1,024\n",
      "│    │    └─attn.c_attn.weight                [1024, 3072]     ├─3,145,728\n",
      "│    │    └─attn.c_attn.bias                  [3072]           ├─3,072\n",
      "│    │    └─attn.c_proj.weight                [1024, 1024]     ├─1,048,576\n",
      "│    │    └─attn.c_proj.bias                  [1024]           ├─1,024\n",
      "│    │    └─ln_2.weight                       [1024]           ├─1,024\n",
      "│    │    └─ln_2.bias                         [1024]           ├─1,024\n",
      "│    │    └─mlp.c_fc.weight                   [1024, 4096]     ├─4,194,304\n",
      "│    │    └─mlp.c_fc.bias                     [4096]           ├─4,096\n",
      "│    │    └─mlp.c_proj.weight                 [4096, 1024]     ├─4,194,304\n",
      "│    │    └─mlp.c_proj.bias                   [1024]           └─1,024\n",
      "│    │    └─LayerNorm (ln_1)                  --               2,048              0.01%\n",
      "│    │    │    └─weight                       [1024]           ├─1,024\n",
      "│    │    │    └─bias                         [1024]           └─1,024\n",
      "│    │    └─Attention (attn)                  --               4,198,400         16.59%\n",
      "│    │    │    └─c_attn.weight                [1024, 3072]     ├─3,145,728\n",
      "│    │    │    └─c_attn.bias                  [3072]           ├─3,072\n",
      "│    │    │    └─c_proj.weight                [1024, 1024]     ├─1,048,576\n",
      "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
      "│    │    └─LayerNorm (ln_2)                  --               2,048              0.01%\n",
      "│    │    │    └─weight                       [1024]           ├─1,024\n",
      "│    │    │    └─bias                         [1024]           └─1,024\n",
      "│    │    └─MLP (mlp)                         --               8,393,728         33.17%\n",
      "│    │    │    └─c_fc.weight                  [1024, 4096]     ├─4,194,304\n",
      "│    │    │    └─c_fc.bias                    [4096]           ├─4,096\n",
      "│    │    │    └─c_proj.weight                [4096, 1024]     ├─4,194,304\n",
      "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
      "├─LayerNorm (ln_f)                            --               2,048              0.01%\n",
      "│    └─weight                                 [1024]           ├─1,024\n",
      "│    └─bias                                   [1024]           └─1,024\n",
      "├─Linear (lm_head)                            --               55,296             0.22%\n",
      "│    └─weight                                 [1024, 54]       └─55,296\n",
      "=============================================================================================\n",
      "Total params: 25,305,088\n",
      "Trainable params: 25,305,088\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 64.48\n",
      "=============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 25.22\n",
      "Params size (MB): 101.22\n",
      "Estimated Total Size (MB): 126.44\n",
      "=============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=============================================================================================\n",
       "Layer (type (var_name))                       Kernel Shape     Param #          Param %\n",
       "=============================================================================================\n",
       "Causal_Transformer (Causal_Transformer)       --               --                    --\n",
       "├─Embedding (wte)                             --               55,296             0.22%\n",
       "│    └─weight                                 [1024, 54]       └─55,296\n",
       "├─Dropout (drop)                              --               --                    --\n",
       "├─ModuleList (h)                              --               --                    --\n",
       "│    └─0.ln_1.weight                          [1024]           ├─1,024\n",
       "│    └─0.ln_1.bias                            [1024]           ├─1,024\n",
       "│    └─0.attn.c_attn.weight                   [1024, 3072]     ├─3,145,728\n",
       "│    └─0.attn.c_attn.bias                     [3072]           ├─3,072\n",
       "│    └─0.attn.c_proj.weight                   [1024, 1024]     ├─1,048,576\n",
       "│    └─0.attn.c_proj.bias                     [1024]           ├─1,024\n",
       "│    └─0.ln_2.weight                          [1024]           ├─1,024\n",
       "│    └─0.ln_2.bias                            [1024]           ├─1,024\n",
       "│    └─0.mlp.c_fc.weight                      [1024, 4096]     ├─4,194,304\n",
       "│    └─0.mlp.c_fc.bias                        [4096]           ├─4,096\n",
       "│    └─0.mlp.c_proj.weight                    [4096, 1024]     ├─4,194,304\n",
       "│    └─0.mlp.c_proj.bias                      [1024]           ├─1,024\n",
       "│    └─1.ln_1.weight                          [1024]           ├─1,024\n",
       "│    └─1.ln_1.bias                            [1024]           ├─1,024\n",
       "│    └─1.attn.c_attn.weight                   [1024, 3072]     ├─3,145,728\n",
       "│    └─1.attn.c_attn.bias                     [3072]           ├─3,072\n",
       "│    └─1.attn.c_proj.weight                   [1024, 1024]     ├─1,048,576\n",
       "│    └─1.attn.c_proj.bias                     [1024]           ├─1,024\n",
       "│    └─1.ln_2.weight                          [1024]           ├─1,024\n",
       "│    └─1.ln_2.bias                            [1024]           ├─1,024\n",
       "│    └─1.mlp.c_fc.weight                      [1024, 4096]     ├─4,194,304\n",
       "│    └─1.mlp.c_fc.bias                        [4096]           ├─4,096\n",
       "│    └─1.mlp.c_proj.weight                    [4096, 1024]     ├─4,194,304\n",
       "│    └─1.mlp.c_proj.bias                      [1024]           └─1,024\n",
       "│    └─Block (0)                              --               --                    --\n",
       "│    │    └─ln_1.weight                       [1024]           ├─1,024\n",
       "│    │    └─ln_1.bias                         [1024]           ├─1,024\n",
       "│    │    └─attn.c_attn.weight                [1024, 3072]     ├─3,145,728\n",
       "│    │    └─attn.c_attn.bias                  [3072]           ├─3,072\n",
       "│    │    └─attn.c_proj.weight                [1024, 1024]     ├─1,048,576\n",
       "│    │    └─attn.c_proj.bias                  [1024]           ├─1,024\n",
       "│    │    └─ln_2.weight                       [1024]           ├─1,024\n",
       "│    │    └─ln_2.bias                         [1024]           ├─1,024\n",
       "│    │    └─mlp.c_fc.weight                   [1024, 4096]     ├─4,194,304\n",
       "│    │    └─mlp.c_fc.bias                     [4096]           ├─4,096\n",
       "│    │    └─mlp.c_proj.weight                 [4096, 1024]     ├─4,194,304\n",
       "│    │    └─mlp.c_proj.bias                   [1024]           └─1,024\n",
       "│    │    └─LayerNorm (ln_1)                  --               2,048              0.01%\n",
       "│    │    │    └─weight                       [1024]           ├─1,024\n",
       "│    │    │    └─bias                         [1024]           └─1,024\n",
       "│    │    └─Attention (attn)                  --               4,198,400         16.59%\n",
       "│    │    │    └─c_attn.weight                [1024, 3072]     ├─3,145,728\n",
       "│    │    │    └─c_attn.bias                  [3072]           ├─3,072\n",
       "│    │    │    └─c_proj.weight                [1024, 1024]     ├─1,048,576\n",
       "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
       "│    │    └─LayerNorm (ln_2)                  --               2,048              0.01%\n",
       "│    │    │    └─weight                       [1024]           ├─1,024\n",
       "│    │    │    └─bias                         [1024]           └─1,024\n",
       "│    │    └─MLP (mlp)                         --               8,393,728         33.17%\n",
       "│    │    │    └─c_fc.weight                  [1024, 4096]     ├─4,194,304\n",
       "│    │    │    └─c_fc.bias                    [4096]           ├─4,096\n",
       "│    │    │    └─c_proj.weight                [4096, 1024]     ├─4,194,304\n",
       "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
       "│    └─Block (1)                              --               --                    --\n",
       "│    │    └─ln_1.weight                       [1024]           ├─1,024\n",
       "│    │    └─ln_1.bias                         [1024]           ├─1,024\n",
       "│    │    └─attn.c_attn.weight                [1024, 3072]     ├─3,145,728\n",
       "│    │    └─attn.c_attn.bias                  [3072]           ├─3,072\n",
       "│    │    └─attn.c_proj.weight                [1024, 1024]     ├─1,048,576\n",
       "│    │    └─attn.c_proj.bias                  [1024]           ├─1,024\n",
       "│    │    └─ln_2.weight                       [1024]           ├─1,024\n",
       "│    │    └─ln_2.bias                         [1024]           ├─1,024\n",
       "│    │    └─mlp.c_fc.weight                   [1024, 4096]     ├─4,194,304\n",
       "│    │    └─mlp.c_fc.bias                     [4096]           ├─4,096\n",
       "│    │    └─mlp.c_proj.weight                 [4096, 1024]     ├─4,194,304\n",
       "│    │    └─mlp.c_proj.bias                   [1024]           └─1,024\n",
       "│    │    └─LayerNorm (ln_1)                  --               2,048              0.01%\n",
       "│    │    │    └─weight                       [1024]           ├─1,024\n",
       "│    │    │    └─bias                         [1024]           └─1,024\n",
       "│    │    └─Attention (attn)                  --               4,198,400         16.59%\n",
       "│    │    │    └─c_attn.weight                [1024, 3072]     ├─3,145,728\n",
       "│    │    │    └─c_attn.bias                  [3072]           ├─3,072\n",
       "│    │    │    └─c_proj.weight                [1024, 1024]     ├─1,048,576\n",
       "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
       "│    │    └─LayerNorm (ln_2)                  --               2,048              0.01%\n",
       "│    │    │    └─weight                       [1024]           ├─1,024\n",
       "│    │    │    └─bias                         [1024]           └─1,024\n",
       "│    │    └─MLP (mlp)                         --               8,393,728         33.17%\n",
       "│    │    │    └─c_fc.weight                  [1024, 4096]     ├─4,194,304\n",
       "│    │    │    └─c_fc.bias                    [4096]           ├─4,096\n",
       "│    │    │    └─c_proj.weight                [4096, 1024]     ├─4,194,304\n",
       "│    │    │    └─c_proj.bias                  [1024]           └─1,024\n",
       "├─LayerNorm (ln_f)                            --               2,048              0.01%\n",
       "│    └─weight                                 [1024]           ├─1,024\n",
       "│    └─bias                                   [1024]           └─1,024\n",
       "├─Linear (lm_head)                            --               55,296             0.22%\n",
       "│    └─weight                                 [1024, 54]       └─55,296\n",
       "=============================================================================================\n",
       "Total params: 25,305,088\n",
       "Trainable params: 25,305,088\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 64.48\n",
       "=============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 25.22\n",
       "Params size (MB): 101.22\n",
       "Estimated Total Size (MB): 126.44\n",
       "============================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "References: https://github.com/TylerYep/torchinfo\n",
    "\"\"\"\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    (1, 128),\n",
    "    dtypes=[torch.long],\n",
    "    verbose=2,\n",
    "    col_width=16,\n",
    "    col_names=[\n",
    "        \"kernel_size\", \n",
    "        #\"output_size\", \n",
    "        \"num_params\", \n",
    "        \"params_percent\"\n",
    "    ],\n",
    "    row_settings=[\"var_names\"],\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infr Outside Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "os.chdir(\"../scripts/causal_transformer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:00<00:00, 1945.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tester.py --handle 0412_000916 --test_files \"val ood_test bigram_test\" counting_samesymbol_addbigram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "output_dir = \"output\"\n",
    "for handle in tqdm(sorted(os.listdir(output_dir))):\n",
    "    #if handle > \"0422_170000\": continue\n",
    "    config = json.load(open(f\"{output_dir}/{handle}/config.json\", \"r\"))\n",
    "    if 'task' in config:\n",
    "        task = config['task']\n",
    "    elif 'data_path' in config:\n",
    "        task = config['data_path'].split(\"/\")[-1]\n",
    "    else:\n",
    "        print(handle)\n",
    "        continue\n",
    "    if 'rotary_posemb' in config and config['rotary_posemb']: continue\n",
    "    if task in [\"counting_samesymbol_addbigram\"]:\n",
    "        test_files = [\"ood_test\", \"bigram_test\"]\n",
    "        if \"test_files\" in config: test_files = config[\"test_files\"]\n",
    "        command = \"python tester.py --handle {} --test_files \\\"{}\\\"\".format(handle, \" \".join([\"val\"]+test_files))\n",
    "        print(command, task)\n",
    "    \n",
    "        #subprocess.check_call(command,stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        #os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'python tester.py --handle 0411_000611 --test_files \"val ood_test\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seen_len for counting_samesymbol_addbigram = 50\n",
      " val acc, load from 0_31563_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 0_31563_transformer.pt\n",
      "                | Test Loss: 4.6777 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 0_31563_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 1_63126_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 1_63126_transformer.pt\n",
      "                | Test Loss: 3.615 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 1_63126_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 2_94689_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 2_94689_transformer.pt\n",
      "                | Test Loss: 3.1836 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 2_94689_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 3_126252_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 3_126252_transformer.pt\n",
      "                | Test Loss: 10.5603 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 3_126252_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 4_157815_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 4_157815_transformer.pt\n",
      "                | Test Loss: 10.6146 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 4_157815_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 5_189378_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 5_189378_transformer.pt\n",
      "                | Test Loss: 3.0447 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 5_189378_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 6_220941_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 6_220941_transformer.pt\n",
      "                | Test Loss: 21.0862 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 6_220941_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 7_252504_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 7_252504_transformer.pt\n",
      "                | Test Loss: 28.0572 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 7_252504_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 8_284067_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 8_284067_transformer.pt\n",
      "                | Test Loss: 17.9877 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 8_284067_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n",
      " val acc, load from 9_315630_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: -1\n",
      "            \n",
      " ood_test acc, load from 9_315630_transformer.pt\n",
      "                | Test Loss: 25.2861 \n",
      "                | Test Acc: 0.6623 \n",
      "                | Test Counting Acc: 0.6711 \n",
      "                | Test Last Acc: 0.0\n",
      "                | Test Unseen Len Acc: 0.0\n",
      "            \n",
      " bigram_test acc, load from 9_315630_transformer.pt\n",
      "                | Test Loss: 0.0 \n",
      "                | Test Acc: 1.0 \n",
      "                | Test Counting Acc: 1.0 \n",
      "                | Test Last Acc: 1.0\n",
      "                | Test Unseen Len Acc: 1.0\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Infr Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/193 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../scripts/causal_transformer/output/0422_150333/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m tqdm(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scripts/causal_transformer/output/\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m      3\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0422_150333\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scripts/causal_transformer/output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhandle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m infr_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scripts/causal_transformer/output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhandle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test_samples/\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m      6\u001b[0m         J \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scripts/causal_transformer/output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhandle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test_samples/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfr_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../scripts/causal_transformer/output/0422_150333/'"
     ]
    }
   ],
   "source": [
    "test_unseen_len_acc = defaultdict(list)\n",
    "for handle in tqdm(os.listdir(\"../scripts/causal_transformer/output/\")):\n",
    "    handle = \"0422_150333\"\n",
    "    if not \"test_samples\" in os.listdir(f\"../scripts/causal_transformer/output/{handle}/\"): continue\n",
    "    for infr_file in sorted(os.listdir(f\"../scripts/causal_transformer/output/{handle}/test_samples/\")):\n",
    "        J = json.load(open(f\"../scripts/causal_transformer/output/{handle}/test_samples/{infr_file}\", \"r\"))\n",
    "        if \"ood_test.txt\" not in J['test_data_file']: continue\n",
    "        #if \"test_unseen_len_acc\" in J: continue\n",
    "        task = J['test_data_file'].split(\"/\")[-2]\n",
    "        if not \"_mod\" in task: continue\n",
    "        val_file = open(f\"../data/rasp_primitives/{task}/val.txt\", \"r\").readlines()\n",
    "        max_seen_len = max([len([x for x in json.loads(l)[0] if x != \"<pad>\"]) for l in val_file])\n",
    "        print(f\"max_seen_len for {task} = {max_seen_len}\")\n",
    "        unseen_len_correct = 0\n",
    "        unseen_len_total = 0\n",
    "        for k in J['testing_output']:\n",
    "            instance = J['testing_output'][k]\n",
    "            gth = np.array([int(x) for x in instance['gth'].split()])\n",
    "            pred = np.array([int(x) for x in instance['pred'].split()])\n",
    "            unseen_len_correct += (gth[gth != -1] == pred[gth != -1])[max_seen_len:].sum()\n",
    "            unseen_len_total += gth[gth != -1][max_seen_len:].size\n",
    "        \n",
    "        if unseen_len_total == 0: \n",
    "            print(\"!!! division by zero !!!\", handle, infr_file)\n",
    "            continue\n",
    "        \n",
    "        J['test_unseen_len_acc'] = round(unseen_len_correct/unseen_len_total, 4)\n",
    "        print(handle, infr_file, J['test_unseen_len_acc'])\n",
    "        # with open(f\"../scripts/causal_transformer/output/{handle}/test_samples/{infr_file}\", \"w\") as f:\n",
    "        #     json.dump(J, f, indent=2, sort_keys=True)\n",
    "        load_from_epoch = J['load_from'].split(\"/\")[-1].split(\"_\")[0]\n",
    "        test_unseen_len_acc[task].append((J['test_unseen_len_acc'], int(load_from_epoch)))\n",
    "        #assert False\n",
    "    break\n",
    "        \n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gth[gth != -1][max_seen_len:].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[gth != -1][max_seen_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_config = {\n",
    "    \"num_hidden_layers\": 2,\n",
    "    \"num_attention_heads\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:00<00:00, 162.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test_unseen_len_acc = defaultdict(list)\n",
    "for handle in tqdm(os.listdir(\"../scripts/causal_transformer/output/\")):\n",
    "    if not \"test_samples\" in os.listdir(f\"../scripts/causal_transformer/output/{handle}/\"): continue\n",
    "    best_test_acc_and_epoch = (0, 0)\n",
    "    for infr_file in os.listdir(f\"../scripts/causal_transformer/output/{handle}/test_samples/\"):\n",
    "        J = json.load(open(f\"../scripts/causal_transformer/output/{handle}/test_samples/{infr_file}\", \"r\"))\n",
    "        if \"ood_test.txt\" not in J['test_data_file']: continue\n",
    "        #if \"test_unseen_len_acc\" in J: continue\n",
    "        task = J['test_data_file'].split(\"/\")[-2]\n",
    "        if not \"_mod\" in task: continue\n",
    "        \n",
    "        config = json.load(open(f\"../scripts/causal_transformer/output/{handle}/config.json\", \"r\"))\n",
    "        flag = True\n",
    "        for k in required_config:\n",
    "            if required_config[k] != config[k]: flag = False\n",
    "        if not flag: continue\n",
    "        \n",
    "        if J['test_unseen_len_acc'] > best_test_acc_and_epoch[0]:\n",
    "            best_test_acc_and_epoch = (J['test_unseen_len_acc'], int(J['load_from'].split(\"/\")[-1].split(\"_\")[0])+1 )\n",
    "    if best_test_acc_and_epoch[1]>0: test_unseen_len_acc[task].append(best_test_acc_and_epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counting_diffsymbol_mod10': [(1.0, 5)],\n",
       " 'counting_diffsymbol_mod11': [(1.0, 5)],\n",
       " 'counting_diffsymbol_mod13': [(1.0, 5)],\n",
       " 'counting_diffsymbol_mod14': [(1.0, 2)],\n",
       " 'counting_diffsymbol_mod15': [(0.9968, 2)],\n",
       " 'counting_diffsymbol_mod16': [(0.0517, 2), (0.0516, 2), (1.0, 6)],\n",
       " 'counting_diffsymbol_mod17': [(1.0, 5)],\n",
       " 'counting_diffsymbol_mod18': [(0.9995, 5), (0.2233, 5)],\n",
       " 'counting_diffsymbol_mod19': [(0.151, 5), (1.0, 5)],\n",
       " 'counting_diffsymbol_mod20': [(0.289, 5), (0.7404, 3)],\n",
       " 'counting_samesymbol_mod10': [(0.9937, 5)],\n",
       " 'counting_samesymbol_mod11': [(0.9942, 5)],\n",
       " 'counting_samesymbol_mod13': [(1.0, 5)],\n",
       " 'counting_samesymbol_mod14': [(0.9859, 8)],\n",
       " 'counting_samesymbol_mod15': [(1.0, 5)],\n",
       " 'counting_samesymbol_mod16': [(0.9799, 10), (0.9639, 7)],\n",
       " 'counting_samesymbol_mod17': [(0.9995, 2), (0.849, 9)],\n",
       " 'counting_samesymbol_mod18': [(0.9697, 1)],\n",
       " 'counting_samesymbol_mod19': [(0.9993, 5)],\n",
       " 'counting_samesymbol_mod20': [(0.9998, 5)]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_unseen_len_acc = dict(sorted(test_unseen_len_acc.items(), key=lambda x: x[0]))\n",
    "test_unseen_len_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapper = {\n",
    "    \"samesymbol\": \"royalblue\",\n",
    "    \"diffsymbol\": \"purple\",\n",
    "}\n",
    "w = 0.15\n",
    "shift_mapper = {\n",
    "    \"samesymbol\": -w/2,\n",
    "    \"diffsymbol\": w/2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "for task in test_unseen_len_acc:\n",
    "    x = int(task.split(\"_\")[-1].replace(\"mod\", \"\"))\n",
    "    shift = shift_mapper[task.split(\"_\")[1]]\n",
    "    color = color_mapper[task.split(\"_\")[1]]\n",
    "    for i, t in enumerate(test_unseen_len_acc[task]): \n",
    "        plt.bar(\n",
    "            x+shift*(2*i+1), \n",
    "            t[0], \n",
    "            width=w*0.9,\n",
    "            color=color, \n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "for k in color_mapper:\n",
    "    plt.bar(x, 0, label=k, color=color_mapper[k], alpha=0.5)\n",
    "plt.ylabel(\"Test Unseen Len Acc\")\n",
    "plt.xticks(list(range(10, 21)), [f\"mod{i}\" for i in range(10, 21)])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Infr Files to /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/348 [00:04<00:26, 12.46it/s]mv: inter-device move failed: '/home/yingshac/workspace/llms_do_math/scripts/causal_transformer/output/0425_144321/test_samples' to '/data/yingshac/llms_do_math/scripts/causal_transformer/output/0425_144321/test_samples'; unable to remove target: Directory not empty\n",
      "100%|██████████| 348/348 [07:09<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/home/yingshac/workspace/llms_do_math/scripts/causal_transformer/output\"\n",
    "data_output_dir = \"/data/yingshac/llms_do_math/scripts/causal_transformer/output\"\n",
    "for h in tqdm(os.listdir(output_dir)):\n",
    "    folders = [\"test_samples\", \"val_samples\"]\n",
    "    for f in folders:\n",
    "        if f in os.listdir(f\"{output_dir}/{h}\"):\n",
    "            command = f\"mv {output_dir}/{h}/{f} {data_output_dir}/{h}/\"\n",
    "            #print(command)\n",
    "            #os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [00:04<00:00, 82.26it/s] \n"
     ]
    }
   ],
   "source": [
    "# delete tensorboard\n",
    "output_dir = \"/home/yingshac/workspace/llms_do_math/scripts/causal_transformer/output\"\n",
    "for h in tqdm(os.listdir(output_dir)):\n",
    "    if \"tensorboard\" in os.listdir(f\"{output_dir}/{h}\"):\n",
    "        command = f\"rm -r {output_dir}/{h}/tensorboard\"\n",
    "        #print(command)\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rm -r /home/yingshac/workspace/llms_do_math/scripts/causal_transformer/output/0424_235327/tensorboard'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.stack([torch.randint(0, 10, (8, 4)) for i in range(2)])\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
