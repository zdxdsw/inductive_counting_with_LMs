{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingshac/workspace/llms_do_math/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, os, math, sys, random, re, pytz\n",
    "from datetime import datetime\n",
    "timezone = pytz.timezone('America/New_York') \n",
    "import torch\n",
    "sys.path.append(\"../scripts/\")\n",
    "from causal_transformer.model import Causal_Transformer\n",
    "from causal_transformer.config import *\n",
    "from causal_transformer.dataset import sequences_collator\n",
    "from causal_transformer.utils import get_acc\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "task = \"counting_diffsymbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = eval(f\"{task}_Config()\")\n",
    "model = Causal_Transformer(config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from 4_78125_transformer.pt\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"/data/yingshac/llms_do_math/scripts/causal_transformer/output\"\n",
    "load_from_dir = \"0406_161636\"\n",
    "load_from_specific_epc = 5\n",
    "ckpt_dir = os.path.join(ckpt_dir, load_from_dir, \"ckpts\")\n",
    "if load_from_specific_epc is None:\n",
    "    load_from_pt = sorted(os.listdir(ckpt_dir), key=lambda x: int(x.split(\"_\")[1]))[-1]\n",
    "else:\n",
    "    load_from_pt = sorted([x for x in os.listdir(ckpt_dir) if f\"{load_from_specific_epc-1}_\" in x[:4]], key=lambda x: int(x.split(\"_\")[1]))[-1]\n",
    "state_dict = torch.load(os.path.join(ckpt_dir, load_from_pt), map_location=device)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(f\"load from {load_from_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 277.09it/s]\n",
      "Generating ood_test split: 1225 examples [00:00, 80874.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"../data/rasp_primitives/{task}\"\n",
    "split = \"ood_test\"\n",
    "test_data = load_dataset(\n",
    "                    \"text\", \n",
    "                    data_files={split: f\"{data_path}/{split}.txt\"})\n",
    "                \n",
    "collator = partial(sequences_collator, w2i={w:i for i,w in enumerate(config.vocab)}, max_len=config.max_position_embeddings)\n",
    "test_dataloader = DataLoader(test_data[split], shuffle=False, batch_size=config.per_device_train_batch_size, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        | Test Loss: 6.6906 \n",
      "        | Test Acc: 0.75 \n",
      "        | Test Counting Acc: 0.7612 \n",
      "        | Test Last Acc: 0.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "counting_correct, counting_demo, last_correct, last_demo, correct, demo = 0, 0, 0, 0, 0, 0\n",
    "test_losses = []\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "model.eval()\n",
    "testing_output = {}\n",
    "\n",
    "date = datetime.now(timezone).strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "k = 0\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    logits = model(\n",
    "        batch['input_id'].to(device),\n",
    "    )\n",
    "    loss = criterion(\n",
    "        logits.view(-1, logits.size(-1)), # bs*seq_len, vocab_size\n",
    "        batch['label'].view(-1).to(device), # 1, bs*seq_len\n",
    "    )\n",
    "    test_losses.append(loss.detach().item())\n",
    "    _counting_correct, _counting_demo, _last_correct, _last_demo = get_acc(logits.detach().cpu(), batch['label'].detach().cpu(), ignore_index=-1)\n",
    "    counting_correct += _counting_correct\n",
    "    counting_demo += _counting_demo\n",
    "    last_correct += _last_correct\n",
    "    last_demo += _last_demo\n",
    "    correct += (_counting_correct + _last_correct)\n",
    "    demo += (_counting_demo + _last_demo)\n",
    "   \n",
    "    for input_id, gth_id, pred_id in zip(batch['input_id'], batch['label'], logits.argmax(dim=-1)):\n",
    "        input_seq = [config.vocab[i] for i in input_id if config.vocab[i]!='<pad>']\n",
    "        gth_seq = [config.vocab[i] for i in gth_id if i!=-1]\n",
    "        pred_seq = [config.vocab[i] for i in pred_id][:len(gth_seq)]\n",
    "        testing_output[k] = {\n",
    "            \"input\": \" \".join(input_seq),\n",
    "            \"gth\": \" \".join(gth_seq),\n",
    "            \"pred\": \" \".join(pred_seq),\n",
    "        }\n",
    "        k+=1\n",
    "    \n",
    "print(f\"\"\"\n",
    "        | Test Loss: {round(np.mean(test_losses), 4)} \n",
    "        | Test Acc: {round(correct/demo, 4)} \n",
    "        | Test Counting Acc: {round(counting_correct/counting_demo, 4)} \n",
    "        | Test Last Acc: {round(last_correct/last_demo, 4)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"../scripts/causal_transformer/output/{load_from_dir}/test_samples\", exist_ok=True)\n",
    "json.dump({\n",
    "        \"test_data_file\":  f\"{data_path}/{split}.txt\",\n",
    "        \"load_from\": f\"{load_from_dir}/{load_from_pt}\",\n",
    "        \"test_acc\": round(correct/demo, 4),\n",
    "        \"test_counting_acc\": round(counting_correct/counting_demo, 4),\n",
    "        \"test_last_acc\": round(last_correct/last_demo, 4),\n",
    "        \"test_loss\": round(np.mean(test_losses), 4),\n",
    "        \"testing_output\": testing_output,\n",
    "    }, \n",
    "    open(f\"../scripts/causal_transformer/output/{load_from_dir}/test_samples/{date}.json\", \"w\"), indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------+--------------+\n",
      "|        Modules         | #Params | Param shape  |\n",
      "+------------------------+---------+--------------+\n",
      "|       wte.weight       |  131072 | [128, 1024]  |\n",
      "|       wpe.weight       |  131072 | [128, 1024]  |\n",
      "|    h.0.ln_1.weight     |   1024  |    [1024]    |\n",
      "|     h.0.ln_1.bias      |   1024  |    [1024]    |\n",
      "| h.0.attn.c_attn.weight | 3145728 | [1024, 3072] |\n",
      "|  h.0.attn.c_attn.bias  |   3072  |    [3072]    |\n",
      "| h.0.attn.c_proj.weight | 1048576 | [1024, 1024] |\n",
      "|  h.0.attn.c_proj.bias  |   1024  |    [1024]    |\n",
      "|    h.0.ln_2.weight     |   1024  |    [1024]    |\n",
      "|     h.0.ln_2.bias      |   1024  |    [1024]    |\n",
      "|  h.0.mlp.c_fc.weight   | 4194304 | [1024, 4096] |\n",
      "|   h.0.mlp.c_fc.bias    |   4096  |    [4096]    |\n",
      "| h.0.mlp.c_proj.weight  | 4194304 | [4096, 1024] |\n",
      "|  h.0.mlp.c_proj.bias   |   1024  |    [1024]    |\n",
      "|    h.1.ln_1.weight     |   1024  |    [1024]    |\n",
      "|     h.1.ln_1.bias      |   1024  |    [1024]    |\n",
      "| h.1.attn.c_attn.weight | 3145728 | [1024, 3072] |\n",
      "|  h.1.attn.c_attn.bias  |   3072  |    [3072]    |\n",
      "| h.1.attn.c_proj.weight | 1048576 | [1024, 1024] |\n",
      "|  h.1.attn.c_proj.bias  |   1024  |    [1024]    |\n",
      "|    h.1.ln_2.weight     |   1024  |    [1024]    |\n",
      "|     h.1.ln_2.bias      |   1024  |    [1024]    |\n",
      "|  h.1.mlp.c_fc.weight   | 4194304 | [1024, 4096] |\n",
      "|   h.1.mlp.c_fc.bias    |   4096  |    [4096]    |\n",
      "| h.1.mlp.c_proj.weight  | 4194304 | [4096, 1024] |\n",
      "|  h.1.mlp.c_proj.bias   |   1024  |    [1024]    |\n",
      "|    h.2.ln_1.weight     |   1024  |    [1024]    |\n",
      "|     h.2.ln_1.bias      |   1024  |    [1024]    |\n",
      "| h.2.attn.c_attn.weight | 3145728 | [1024, 3072] |\n",
      "|  h.2.attn.c_attn.bias  |   3072  |    [3072]    |\n",
      "| h.2.attn.c_proj.weight | 1048576 | [1024, 1024] |\n",
      "|  h.2.attn.c_proj.bias  |   1024  |    [1024]    |\n",
      "|    h.2.ln_2.weight     |   1024  |    [1024]    |\n",
      "|     h.2.ln_2.bias      |   1024  |    [1024]    |\n",
      "|  h.2.mlp.c_fc.weight   | 4194304 | [1024, 4096] |\n",
      "|   h.2.mlp.c_fc.bias    |   4096  |    [4096]    |\n",
      "| h.2.mlp.c_proj.weight  | 4194304 | [4096, 1024] |\n",
      "|  h.2.mlp.c_proj.bias   |   1024  |    [1024]    |\n",
      "|    h.3.ln_1.weight     |   1024  |    [1024]    |\n",
      "|     h.3.ln_1.bias      |   1024  |    [1024]    |\n",
      "| h.3.attn.c_attn.weight | 3145728 | [1024, 3072] |\n",
      "|  h.3.attn.c_attn.bias  |   3072  |    [3072]    |\n",
      "| h.3.attn.c_proj.weight | 1048576 | [1024, 1024] |\n",
      "|  h.3.attn.c_proj.bias  |   1024  |    [1024]    |\n",
      "|    h.3.ln_2.weight     |   1024  |    [1024]    |\n",
      "|     h.3.ln_2.bias      |   1024  |    [1024]    |\n",
      "|  h.3.mlp.c_fc.weight   | 4194304 | [1024, 4096] |\n",
      "|   h.3.mlp.c_fc.bias    |   4096  |    [4096]    |\n",
      "| h.3.mlp.c_proj.weight  | 4194304 | [4096, 1024] |\n",
      "|  h.3.mlp.c_proj.bias   |   1024  |    [1024]    |\n",
      "|      ln_f.weight       |   1024  |    [1024]    |\n",
      "|       ln_f.bias        |   1024  |    [1024]    |\n",
      "|     lm_head.weight     |  131072 | [128, 1024]  |\n",
      "+------------------------+---------+--------------+\n",
      "Total Params: 50780160\n"
     ]
    }
   ],
   "source": [
    "from causal_transformer.utils import count_parameters\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"j\", \"a\", \"v\", \"k\", \"e\", \"z\", \"a\", \"a\", \"g\", \"b\", \"r\", \"q\", \"o\", \"g\", \"x\", \"x\", \"w\", \"u\", \"i\", \"s\", \"b\", \"z\", \"t\", \"o\", \"v\", \"t\", \"r\", \"b\", \"s\", \"v\", \"f\", \"y\", \"q\", \"m\", \"z\", \"z\", \"n\", \"x\", \"r\", \"n\", \"l\", \"c\", \"r\", \"g\", \"s\", \"f\", \"t\", \"i\", \"x\", \"q\", \"e\", \"b\", \"x\", \"v\", \"d\", \"c\", \"b\", \"f\", \"t\", \"b\", \"b\", \"f\", \"e\", \"d\", \"a\", \"s\", \"b\", \"m\", \"z\", \"f\", \"d\", \"s\", \"r\", \"r\", \"r\", \"l\", \"x\", \"b\", \"w\", \"j\", \"r\", \"v\", \"u\", \"d\", \"z\", \"m\", \"v\", \"z\", \"y\", \"v\", \"i\", \"k\", \"n\", \"f\", \"m\", \"g\", \"r\", \"t\", \"m\", \"1\"]), len([\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_do_math",
   "language": "python",
   "name": "llms_do_math"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
